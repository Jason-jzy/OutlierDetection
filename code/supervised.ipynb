{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/creditcard.csv')\n",
    "x = np.array(data.loc[1:len(data)-1, 'Time'])\n",
    "y = np.array(data.loc[0:len(data)-2, 'Time'])\n",
    "data.loc[1:, 'Time'] = x-y\n",
    "normal = data[data['Class']==0]\n",
    "anomaly = data[data['Class']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Train: (170589, 31) Normal Valid: (56863, 31) Normal Test: (56863, 31)\n",
      "Anomaly Train: (295, 31) Anomaly Valid: (98, 31) Anomaly Test: (99, 31)\n"
     ]
    }
   ],
   "source": [
    "train_normal, test_normal = train_test_split(normal, test_size=0.4, random_state=42)\n",
    "valid_normal, test_normal = train_test_split(test_normal, test_size=0.5, random_state=42)\n",
    "train_anomaly, test_anomaly = train_test_split(anomaly, test_size=0.4, random_state=42)\n",
    "valid_anomaly, test_anomaly = train_test_split(test_anomaly, test_size=0.5, random_state=42)\n",
    "\n",
    "for x in [train_normal, valid_normal, test_normal, train_anomaly, valid_anomaly, test_anomaly]:\n",
    "    x.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print('Normal Train:', train_normal.shape, \n",
    "      'Normal Valid:', valid_normal.shape, \n",
    "      'Normal Test:', test_normal.shape)\n",
    "print('Anomaly Train:', train_anomaly.shape, \n",
    "      'Anomaly Valid:', valid_anomaly.shape, \n",
    "      'Anomaly Test:', test_anomaly.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_normal.append(train_anomaly).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "valid = valid_normal.append(valid_anomaly).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test = test_normal.append(test_anomaly).sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data(model):\n",
    "    x = train\n",
    "    predict_model = model.predict(x.drop(columns=['Class']))\n",
    "    recall_model = recall_score(y_true=x['Class'].values, y_pred=predict_model)\n",
    "    precision_model = precision_score(y_true=x['Class'].values, y_pred=predict_model)\n",
    "    fbeta_model = fbeta_score(y_true=x['Class'].values, y_pred=predict_model, beta=1.5)\n",
    "\n",
    "    print('Train Recall:', recall_model, \n",
    "          '\\nTrain Precision:', precision_model, \n",
    "          '\\nTrain F-score:', fbeta_model)\n",
    "    cnf_matrix_model = confusion_matrix(y_true=x['Class'].values, y_pred=predict_model)\n",
    "    print('Train Confusion Matrix: ')\n",
    "    print(cnf_matrix_model)\n",
    "    \n",
    "\n",
    "    x = valid\n",
    "    predict_model = model.predict(x.drop(columns=['Class']))\n",
    "    recall_model = recall_score(y_true=x['Class'].values, y_pred=predict_model)\n",
    "    precision_model = precision_score(y_true=x['Class'].values, y_pred=predict_model)\n",
    "    fbeta_model = fbeta_score(y_true=x['Class'].values, y_pred=predict_model, beta=1.5)\n",
    "\n",
    "    print('Valid Recall:', recall_model, \n",
    "          '\\nValid Precision:', precision_model, \n",
    "          '\\nValid F-score:', fbeta_model)\n",
    "    cnf_matrix_model = confusion_matrix(y_true=x['Class'].values, y_pred=predict_model)\n",
    "    print('Valid Confusion Matrix: ')\n",
    "    print(cnf_matrix_model)\n",
    "    \n",
    "\n",
    "    x = test\n",
    "    predict_model = model.predict(x.drop(columns=['Class']))\n",
    "    recall_model = recall_score(y_true=x['Class'].values, y_pred=predict_model)\n",
    "    precision_model = precision_score(y_true=x['Class'].values, y_pred=predict_model)\n",
    "    fbeta_model = fbeta_score(y_true=x['Class'].values, y_pred=predict_model, beta=1.5)\n",
    "\n",
    "    print('Test Recall:', recall_model, \n",
    "          '\\nTest Precision:', precision_model, \n",
    "          '\\nTest F-score:', fbeta_model)\n",
    "\n",
    "    cnf_matrix_model = confusion_matrix(y_true=x['Class'].values, y_pred=predict_model)\n",
    "    print('Test Confusion Matrix: ')\n",
    "    print(cnf_matrix_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall: 0.5864406779661017 \n",
      "Train Precision: 0.8522167487684729 \n",
      "Train F-score: 0.6486876261897894\n",
      "Train Confusion Matrix: \n",
      "[[170559     30]\n",
      " [   122    173]]\n",
      "Valid Recall: 0.6122448979591837 \n",
      "Valid Precision: 0.8823529411764706 \n",
      "Valid F-score: 0.6759098786828422\n",
      "Valid Confusion Matrix: \n",
      "[[56855     8]\n",
      " [   38    60]]\n",
      "Test Recall: 0.5959595959595959 \n",
      "Test Precision: 0.8676470588235294 \n",
      "Test F-score: 0.6595012897678417\n",
      "Test Confusion Matrix: \n",
      "[[56854     9]\n",
      " [   40    59]]\n"
     ]
    }
   ],
   "source": [
    "logistic = LogisticRegression(random_state=0, solver='newton-cg',\n",
    "                         multi_class='multinomial')\n",
    "logistic.fit(train.drop(columns=['Class']), train['Class'])\n",
    "\n",
    "print_data(logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall: 0.823728813559322 \n",
      "Train Precision: 0.058766626360338574 \n",
      "Train F-score: 0.1645741078405835\n",
      "Train Confusion Matrix: \n",
      "[[166697   3892]\n",
      " [    52    243]]\n",
      "Valid Recall: 0.8469387755102041 \n",
      "Valid Precision: 0.06102941176470588 \n",
      "Valid F-score: 0.17067383739322997\n",
      "Valid Confusion Matrix: \n",
      "[[55586  1277]\n",
      " [   15    83]]\n",
      "Test Recall: 0.8282828282828283 \n",
      "Test Precision: 0.05758426966292135 \n",
      "Test F-score: 0.1618339152876879\n",
      "Test Confusion Matrix: \n",
      "[[55521  1342]\n",
      " [   17    82]]\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(train.drop(columns=['Class']), train['Class'])\n",
    "\n",
    "print_data(gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall: 0.7762711864406779 \n",
      "Train Precision: 1.0 \n",
      "Train F-score: 0.8336600392047046\n",
      "Train Confusion Matrix: \n",
      "[[170589      0]\n",
      " [    66    229]]\n",
      "Valid Recall: 0.7551020408163265 \n",
      "Valid Precision: 0.8809523809523809 \n",
      "Valid F-score: 0.7898193760262725\n",
      "Valid Confusion Matrix: \n",
      "[[56853    10]\n",
      " [   24    74]]\n",
      "Test Recall: 0.7171717171717171 \n",
      "Test Precision: 0.8987341772151899 \n",
      "Test F-score: 0.764705882352941\n",
      "Test Confusion Matrix: \n",
      "[[56855     8]\n",
      " [   28    71]]\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(criterion='gini', max_depth=6, class_weight={0:5, 1:1})\n",
    "tree.fit(train.drop(columns=['Class']), train['Class'])\n",
    "\n",
    "print_data(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall: 0.7423728813559322 \n",
      "Train Precision: 0.85546875 \n",
      "Train F-score: 0.773851590106007\n",
      "Train Confusion Matrix: \n",
      "[[170552     37]\n",
      " [    76    219]]\n",
      "Valid Recall: 0.826530612244898 \n",
      "Valid Precision: 0.8804347826086957 \n",
      "Valid F-score: 0.8423999999999999\n",
      "Valid Confusion Matrix: \n",
      "[[56852    11]\n",
      " [   17    81]]\n",
      "Test Recall: 0.7777777777777778 \n",
      "Test Precision: 0.875 \n",
      "Test F-score: 0.8053097345132745\n",
      "Test Confusion Matrix: \n",
      "[[56852    11]\n",
      " [   22    77]]\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(train.drop(columns=['Class']), train['Class'])\n",
    "\n",
    "print_data(lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall: 0.7491525423728813 \n",
      "Train Precision: 0.8565891472868217 \n",
      "Train F-score: 0.779224301600217\n",
      "Train Confusion Matrix: \n",
      "[[170552     37]\n",
      " [    74    221]]\n",
      "Valid Recall: 0.826530612244898 \n",
      "Valid Precision: 0.8804347826086957 \n",
      "Valid F-score: 0.8423999999999999\n",
      "Valid Confusion Matrix: \n",
      "[[56852    11]\n",
      " [   17    81]]\n",
      "Test Recall: 0.7777777777777778 \n",
      "Test Precision: 0.875 \n",
      "Test F-score: 0.8053097345132745\n",
      "Test Confusion Matrix: \n",
      "[[56852    11]\n",
      " [   22    77]]\n"
     ]
    }
   ],
   "source": [
    "lda_bagging = BaggingClassifier(LinearDiscriminantAnalysis(), n_estimators=5)\n",
    "lda_bagging.fit(train.drop(columns=['Class']), train['Class'])\n",
    "\n",
    "print_data(lda_bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall: 0.8745762711864407 \n",
      "Train Precision: 0.05386221294363257 \n",
      "Train F-score: 0.15374742149896858\n",
      "Train Confusion Matrix: \n",
      "[[166057   4532]\n",
      " [    37    258]]\n",
      "Valid Recall: 0.9081632653061225 \n",
      "Valid Precision: 0.056400506970849175 \n",
      "Valid F-score: 0.1608284681679177\n",
      "Valid Confusion Matrix: \n",
      "[[55374  1489]\n",
      " [    9    89]]\n",
      "Test Recall: 0.8484848484848485 \n",
      "Test Precision: 0.05286343612334802 \n",
      "Test F-score: 0.15068304125845175\n",
      "Test Confusion Matrix: \n",
      "[[55358  1505]\n",
      " [   15    84]]\n"
     ]
    }
   ],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(train.drop(columns=['Class']), train['Class'])\n",
    "\n",
    "print_data(qda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall: 0.8711864406779661 \n",
      "Train Precision: 0.057961208840775824 \n",
      "Train F-score: 0.16384679515472514\n",
      "Train Confusion Matrix: \n",
      "[[166412   4177]\n",
      " [    38    257]]\n",
      "Valid Recall: 0.9081632653061225 \n",
      "Valid Precision: 0.060792349726775954 \n",
      "Valid F-score: 0.17171267438409027\n",
      "Valid Confusion Matrix: \n",
      "[[55488  1375]\n",
      " [    9    89]]\n",
      "Test Recall: 0.8484848484848485 \n",
      "Test Precision: 0.057455540355677154 \n",
      "Test F-score: 0.16204184597121235\n",
      "Test Confusion Matrix: \n",
      "[[55485  1378]\n",
      " [   15    84]]\n"
     ]
    }
   ],
   "source": [
    "qda_bagging = BaggingClassifier(QuadraticDiscriminantAnalysis(), n_estimators=11)\n",
    "qda_bagging.fit(train.drop(columns=['Class']), train['Class'])\n",
    "\n",
    "print_data(qda_bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall: 0.7559322033898305 \n",
      "Train Precision: 0.8415094339622642 \n",
      "Train F-score: 0.780349932705249\n",
      "Train Confusion Matrix: \n",
      "[[170547     42]\n",
      " [    72    223]]\n",
      "Valid Recall: 0.8367346938775511 \n",
      "Valid Precision: 0.8631578947368421 \n",
      "Valid F-score: 0.8446909667194928\n",
      "Valid Confusion Matrix: \n",
      "[[56850    13]\n",
      " [   16    82]]\n",
      "Test Recall: 0.797979797979798 \n",
      "Test Precision: 0.8494623655913979 \n",
      "Test F-score: 0.8131433095803642\n",
      "Test Confusion Matrix: \n",
      "[[56849    14]\n",
      " [   20    79]]\n"
     ]
    }
   ],
   "source": [
    "classifier = [('lda', lda), ('qda', qda), ('log', logistic)]\n",
    "vote = VotingClassifier(classifier)\n",
    "\n",
    "vote.fit(train.drop(columns=['Class']), train['Class'])\n",
    "\n",
    "print_data(vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiazeyu/anaconda3/envs/ml/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall: 0.9525423728813559 \n",
      "Train Precision: 0.9964539007092199 \n",
      "Train F-score: 0.9656357388316151\n",
      "Train Confusion Matrix: \n",
      "[[170588      1]\n",
      " [    14    281]]\n",
      "Valid Recall: 0.8163265306122449 \n",
      "Valid Precision: 0.9411764705882353 \n",
      "Valid F-score: 0.8510638297872339\n",
      "Valid Confusion Matrix: \n",
      "[[56858     5]\n",
      " [   18    80]]\n",
      "Test Recall: 0.7676767676767676 \n",
      "Test Precision: 0.9620253164556962 \n",
      "Test F-score: 0.8185584092792045\n",
      "Test Confusion Matrix: \n",
      "[[56860     3]\n",
      " [   23    76]]\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(train.drop(columns=['Class']), train['Class'])\n",
    "\n",
    "print_data(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall: 0.7661016949152543 \n",
      "Train Precision: 0.029639344262295083 \n",
      "Train F-score: 0.08861408535665813\n",
      "Train Confusion Matrix: \n",
      "[[163190   7399]\n",
      " [    69    226]]\n",
      "Valid Recall: 0.7959183673469388 \n",
      "Valid Precision: 0.031075697211155377 \n",
      "Valid F-score: 0.09284013916865042\n",
      "Valid Confusion Matrix: \n",
      "[[54431  2432]\n",
      " [   20    78]]\n",
      "Test Recall: 0.7878787878787878 \n",
      "Test Precision: 0.031489705288655634 \n",
      "Test F-score: 0.09389758310954718\n",
      "Test Confusion Matrix: \n",
      "[[54464  2399]\n",
      " [   21    78]]\n"
     ]
    }
   ],
   "source": [
    "adb = AdaBoostClassifier(GaussianNB(),\n",
    "                         n_estimators=50)\n",
    "adb.fit(train.drop(columns=['Class']), train['Class'])\n",
    "\n",
    "print_data(adb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall: 0.7796610169491526 \n",
      "Train Precision: 0.8646616541353384 \n",
      "Train F-score: 0.8039795643990321\n",
      "Train Confusion Matrix: \n",
      "[[170553     36]\n",
      " [    65    230]]\n",
      "Valid Recall: 0.826530612244898 \n",
      "Valid Precision: 0.8804347826086957 \n",
      "Valid F-score: 0.8423999999999999\n",
      "Valid Confusion Matrix: \n",
      "[[56852    11]\n",
      " [   17    81]]\n",
      "Test Recall: 0.8080808080808081 \n",
      "Test Precision: 0.851063829787234 \n",
      "Test F-score: 0.8208366219415943\n",
      "Test Confusion Matrix: \n",
      "[[56849    14]\n",
      " [   19    80]]\n"
     ]
    }
   ],
   "source": [
    "nn = MLPClassifier(solver='lbfgs', alpha=1e-4, \n",
    "                   hidden_layer_sizes=(5, 4, 3, 3), random_state=1)\n",
    "nn.fit(train.drop(columns=['Class']), train['Class'])\n",
    "\n",
    "print_data(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall: 0.8745762711864407 \n",
      "Train Precision: 0.9923076923076923 \n",
      "Train F-score: 0.9077131258457375\n",
      "Train Confusion Matrix: \n",
      "[[170587      2]\n",
      " [    37    258]]\n",
      "Valid Recall: 0.826530612244898 \n",
      "Valid Precision: 0.9418604651162791 \n",
      "Valid F-score: 0.8588907014681892\n",
      "Valid Confusion Matrix: \n",
      "[[56858     5]\n",
      " [   17    81]]\n",
      "Test Recall: 0.8080808080808081 \n",
      "Test Precision: 0.9411764705882353 \n",
      "Test F-score: 0.8448415922014622\n",
      "Test Confusion Matrix: \n",
      "[[56858     5]\n",
      " [   19    80]]\n"
     ]
    }
   ],
   "source": [
    "xg = XGBClassifier(max_depth=4, reg_lambda=0.5)\n",
    "xg.fit(train.drop(columns=['Class']), train['Class'])\n",
    "\n",
    "print_data(xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall: 1.0 \n",
      "Train Precision: 1.0 \n",
      "Train F-score: 1.0\n",
      "Train Confusion Matrix: \n",
      "[[170589      0]\n",
      " [     0    295]]\n",
      "Valid Recall: 0.7346938775510204 \n",
      "Valid Precision: 0.8275862068965517 \n",
      "Valid F-score: 0.7609756097560976\n",
      "Valid Confusion Matrix: \n",
      "[[56848    15]\n",
      " [   26    72]]\n",
      "Test Recall: 0.7474747474747475 \n",
      "Test Precision: 0.8131868131868132 \n",
      "Test F-score: 0.7665338645418327\n",
      "Test Confusion Matrix: \n",
      "[[56846    17]\n",
      " [   25    74]]\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(train.drop(columns=['Class']), train['Class'])\n",
    "\n",
    "print_data(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
